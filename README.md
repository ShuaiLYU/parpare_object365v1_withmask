# Prepare Objects365v1 with SAM Masks

## Overview

This repository provides scripts and instructions to prepare the Objects365v1 dataset for YOLO training with segmentation masks generated by the Segment Anything Model (SAM). The workflow includes downloading the dataset, generating high-quality segmentation masks, and converting annotations to YOLO format.

## File Structure
```
parpare_object365v1_withmask/
├── parpare_object365v1.sh          # Script to download and unpack Objects365v1
├── tools/
│   ├── generate_sam_masks.py       # Script to generate SAM masks (adapted from yoloe)
│   └── generate_objects365v1.py    # Script to convert annotations to YOLO format (with val split support)
├── sam2/                           # Directory for SAM model and dependencies
│   └── checkpoints/                # Directory to store SAM model weights
│       └── sam2.1_hiera_large.pt   # Pre-trained SAM model weights
└── README.md                       # This README file
```

## Script Modifications

The scripts in this repository have been adapted from the [YOLOE repository](https://github.com/THU-MIG/yoloe) with the following enhancements:

- **`generate_sam_masks.py`**: Added better error handling and progress reporting
- **`generate_objects365v1.py`**: Extended to support validation split processing (original only handled training split)



## Setup Instructions

### 1. Download and Unpack the Dataset

Run the provided shell script to download and organize the Objects365v1 images and annotations:

```bash
bash parpare_object365v1.sh
```

### 2. Prepare the Python Environment

Create and activate a dedicated environment for SAM processing:

```bash
conda create -n sam2 python=3.10
conda activate sam2
pip install -r third_party/sam2/requirements.txt
pip install -e third_party/sam2/
```

### 3. Download SAM Model Weights

Download the pre-trained SAM2.1 model weights:

```bash
mkdir -p sam2/checkpoints
wget https://huggingface.co/facebook/sam2.1-hiera-large/resolve/main/sam2.1_hiera_large.pt -P sam2/checkpoints
```

### 4. Generate SAM Masks for Validation Split

Use the mask generation script to process images and annotations:

```bash
python tools/generate_sam_masks.py \
  --img-path ../datasets/Objects365v1/images/val \
  --json-path ../datasets/Objects365v1/annotations/objects365_val.json \
  --gpus 0,1,2,3 \
  --batch
```



### 5. Convert to YOLO Format Labels

After mask generation, convert the annotations to YOLO format:

```bash
python tools/generate_objects365v1.py
```

## Important Notes

- **Processing Time**: The mask generation process is computationally intensive and may take several hours or days depending on your hardware.
- **GPU Requirements**: While not strictly required, a GPU with sufficient VRAM will significantly speed up the process.
- **Error Handling**: The scripts include improved error handling to continue processing even if individual images fail.

